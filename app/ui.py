# app/ui.py

import os
import json
import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from io import BytesIO
from datetime import datetime
from constants import STRUCTURES, DISPLAY_NAMES, CONSTRAINTS, PARAM_ORDER, GA_DEFAULTS
from utils import patch_selectbox, parse_params_string
from ml import load_model_and_scalers, predict_em_properties
from db import (
    init_db,
    save_ga_result,
    save_trained_model_to_db,
    save_graph_to_db,
    get_training_graphs,
)

from ga import (
    random_individual,
    load_initial_population,
    mutate,
    crossover,
    fitness_batch,
    reintroduce_diversity
)
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import tensorflow as tf
import joblib
import random

gpus = tf.config.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
    except RuntimeError as e:
        print(e)

def run_app():
    # –ü–∞—Ç—á–∏–º selectbox –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã—Ö –Ω–∞–∑–≤–∞–Ω–∏–π
    patch_selectbox()

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –±–∞–∑—É –∏ —Å–æ–∑–¥–∞—ë–º –ø–∞–ø–∫–∏ –¥–ª—è –º–æ–¥–µ–ª–µ–π
    conn = init_db()
    for s in STRUCTURES:
        os.makedirs(f"./models/{s}", exist_ok=True)

    st.title("üõ°Ô∏è –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –≠–ú —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –º–µ—Ç–∞—ç–ª–µ–º–µ–Ω—Ç–∞")

    # –î–ª—è —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ì–ê –∏ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –≤—Ä—É—á–Ω—É—é –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    if 'ga_result' not in st.session_state:
        st.session_state.ga_result = None
    if 'loaded_params' not in st.session_state:
        st.session_state.loaded_params = {}

    tabs = st.tabs([
        "üìà –ù–µ–π—Ä–æ—Å–µ—Ç—å",
        "üéØ –ì–µ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º",
        "üß† –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏",
        "üñºÔ∏è –ì—Ä–∞—Ñ–∏–∫–∏ –ì–ê",
        "üñºÔ∏è –ì—Ä–∞—Ñ–∏–∫–∏ TF"
    ])

    # ===== TAB 1: –ù–µ–π—Ä–æ—Å–µ—Ç—å =====
    with tabs[0]:
        st.subheader("üìà –†–∞—Å—á—ë—Ç –ø–æ H, K, L, P –Ω–µ–π—Ä–æ—Å–µ—Ç—å—é")

        structure = st.selectbox(
            "–§–æ—Ä–º–∞ –º–µ—Ç–∞—ç–ª–µ–º–µ–Ω—Ç–∞", STRUCTURES, key="tab1_structure"
        )
        bounds = CONSTRAINTS[structure]
        model, x_scaler, y_scaler = load_model_and_scalers(structure)

        # –ó–∞–≥—Ä—É–∑–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏–∑ —Å—Ç—Ä–æ–∫–∏
        load_text = st.text_input(
            "üì• –í—Å—Ç–∞–≤—å—Ç–µ '[H K L P]'",
            placeholder="[0.5 1.0 3.0 0.2]"
        )
        # –ö–Ω–æ–ø–∫–∞ ¬´–ó–∞–≥—Ä—É–∑–∏—Ç—å¬ª
        if st.button("üîÑ –ó–∞–≥—Ä—É–∑–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã", key="tab1_load"):
            # 1) –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å—Ç—Ä–æ–∫–∞ –Ω–µ –ø—É—Å—Ç–∞—è
            if not load_text.strip():
                st.error("‚ùó –í—ã –Ω–µ –≤—Å—Ç–∞–≤–∏–ª–∏ –Ω–∏ –æ–¥–Ω–æ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞")
            else:
                # 2) –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å
                try:
                    params = parse_params_string(load_text)
                    st.session_state.loaded_params = params
                    st.success("‚úÖ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
                except Exception as e:
                    st.error(f"–û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞: {e}")

        # –ó–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        defaults = st.session_state.loaded_params
        H = st.number_input("H", *bounds['H'], value=defaults.get('H', sum(bounds['H'])/2), format="%.6f")
        K = st.number_input("K", *bounds['K'], value=defaults.get('K', sum(bounds['K'])/2), format="%.6f")
        L = st.number_input("L", *bounds['L'], value=defaults.get('L', sum(bounds['L'])/2), format="%.6f")
        P = st.number_input("P", *bounds['P'], value=defaults.get('P', sum(bounds['P'])/2), format="%.6f")

        if st.button("üìä –†–∞—Å—Å—á–∏—Ç–∞—Ç—å", key="tab1_predict"):
            try:
                se, ghz, refl, absor = predict_em_properties(model, x_scaler, y_scaler, H, K, L, P)
                st.write(f"**–≠–≠**: {se:.4f} –¥–ë")
                st.write(f"**–ß–∞—Å—Ç–æ—Ç–∞**: {ghz:.4f} –ì–ì—Ü")
                st.write(f"**–û—Ç—Ä–∞–∂–µ–Ω–∏–µ**: {refl:.4f}")
                st.write(f"**–ü–æ–≥–ª–æ—â–µ–Ω–∏–µ**: {absor:.4f}")
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏–∑ –ì–ê, –µ—Å–ª–∏ –µ—Å—Ç—å
        if st.session_state.ga_result:
            st.markdown("---")
            st.markdown("#### üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç –ì–ê")
            r = st.session_state.ga_result
            st.write(f"H,K,L,P: {r['params']}")
            st.write(f"–≠–≠: {r['se']:.4f} –¥–ë, Freq: {r['ghz']:.4f} –ì–ì—Ü")

    # ===== TAB 2: –ì–µ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º =====
    with tabs[1]:
        st.subheader("üéØ –ü–æ–¥–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ì–ê")

        structure = st.selectbox("–§–æ—Ä–º–∞", STRUCTURES, key="tab2_structure")
        bounds = CONSTRAINTS[structure]
        model, x_scaler, y_scaler = load_model_and_scalers(structure)

        # –¢–∞–±–ª–∏—Ü–∞ –ø—Ä–æ—à–ª—ã—Ö –∑–∞–ø—É—Å–∫–æ–≤
        df = pd.read_sql_query(
            "SELECT * FROM ga_results WHERE structure=? ORDER BY run_date ASC",
            conn, params=(structure,)
        )
        if not df.empty:
            df['params'] = df['params'].apply(json.loads)
            df[['H','K','L','P']] = pd.DataFrame(df['params'].tolist(), index=df.index)
            st.dataframe(df.drop(columns=['id','params']))

        # –¶–µ–ª–∏
        target_freq = st.number_input("–¶–µ–ª–µ–≤–∞—è —á–∞—Å—Ç–æ—Ç–∞ (–ì–ì—Ü)", 0.0, 100.0, 10.0, 0.01)
        target_se   = st.number_input("–¶–µ–ª–µ–≤–∞—è –≠–≠ (–¥–ë)",      0.0, 100.0, 30.0, 0.01)

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ì–ê
        with st.expander("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ì–ê"):
            pop_size      = st.slider("–ü–æ–ø—É–ª—è—Ü–∏—è",    20, 300, GA_DEFAULTS['pop_size'],    10)
            generations   = st.slider("–ü–æ–∫–æ–ª–µ–Ω–∏—è",    50, 500, GA_DEFAULTS['generations'],   10)
            mutation_rate = st.slider("–ú—É—Ç–∞—Ü–∏—è",     0.01, 0.5, GA_DEFAULTS['mutation_rate'], 0.01)

        if st.button("üß¨ –ó–∞–ø—É—Å—Ç–∏—Ç—å –ì–ê", key="tab2_run"):
            try:
                st.write(f"–ü–æ–ø={pop_size}, –ü–æ–∫–æ–ª={generations}, Œº={mutation_rate:.2f}")
                param_order = PARAM_ORDER

                # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –Ω–∞—á–∞–ª—å–Ω–æ–π –ø–æ–ø—É–ª—è—Ü–∏–∏
                file = f"./{structure}/cst_data.txt"
                init_cands = load_initial_population(file, target_se, target_freq, bounds, param_order)
                population = init_cands[:pop_size//3]
                while len(population) < pop_size:
                    population.append(random_individual(bounds))

                # –ò—Å—Ç–æ—Ä–∏—è –∏ –ø—Ä–æ–≥—Ä–µ—Å—Å
                best_se_hist, best_freq_hist, fit_hist = [], [], []
                best_inds = []
                found_gen = None
                bar = st.progress(0)

                for gen in range(generations):
                    bar.progress((gen+1)/generations)

                    fits, se_vals, freq_vals = fitness_batch(
                        population, model, x_scaler, y_scaler,
                        target_se, target_freq,
                        w_se=1.0, w_freq=1.5,
                        generation=gen, max_generations=generations
                    )

                    # –∑–∞–ø–æ–º–Ω–∏–º –∏—Å—Ç–æ—Ä–∏—é –ª—É—á—à–µ–π –æ—Å–æ–±–∏ –ø–æ —Ñ–∏—Ç–Ω–µ—Å—É
                    idx_best = int(np.argmax(fits))
                    best_inds.append(population[idx_best].copy())
                    best_se_hist.append(se_vals[idx_best])
                    best_freq_hist.append(freq_vals[idx_best])
                    fit_hist.append(fits[idx_best])

                    # —Ä–∞–Ω–Ω–∏–π –≤—ã—Ö–æ–¥: –æ–±–∞ —É—Å–ª–æ–≤–∏—è
                    if abs(freq_vals[idx_best] - target_freq) <= 0.01 and se_vals[idx_best] >= target_se:
                        found_gen = gen + 1
                        st.info(
                            f"‚èπÔ∏è –¶–µ–ª–µ–≤—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –¥–æ—Å—Ç–∏–≥–Ω—É—Ç—ã –Ω–∞ {found_gen}-–º –ø–æ–∫–æ–ª–µ–Ω–∏–∏: "
                            f"SE={se_vals[idx_best]:.2f} –¥–ë, Freq={freq_vals[idx_best]:.4f} –ì–ì—Ü"
                        )
                        break

                    # —ç–ª–∏—Ç–∏–∑–º + —Å–∫—Ä–µ—â–∏–≤–∞–Ω–∏—è
                    elites = [population[i] for i in np.argsort(fits)[-int(0.1*pop_size):]]
                    new_pop = elites.copy()
                    while len(new_pop) < pop_size:
                        p1, p2 = random.choice(population), random.choice(population)
                        c1, c2 = crossover(p1, p2, bounds)
                        new_pop += [
                            mutate(c1, bounds, mutation_rate, gen, generations),
                            mutate(c2, bounds, mutation_rate, gen, generations)
                        ]
                    population = new_pop[:pop_size]

                    # –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
                    population, _ = reintroduce_diversity(population, fits, gen, mutation_rate, bounds)

                # --- –ø–æ—Å–ª–µ –æ–∫–æ–Ω—á–∞–Ω–∏—è —Ü–∏–∫–ª–∞ –ø–æ–∫–æ–ª–µ–Ω–∏–π ---

                # 1) –í—ã–±–æ—Ä –ø–æ–∫–æ–ª–µ–Ω–∏—è —Å –Ω–∞–∏–±–æ–ª—å—à–µ–π SE –ø—Ä–∏ –¥–æ–ø—É—Å–∫–µ –ø–æ —á–∞—Å—Ç–æ—Ç–µ
                tol = 0.01
                candidates = [
                    (i, se, freq)
                    for i, (se, freq) in enumerate(zip(best_se_hist, best_freq_hist))
                    if abs(freq - target_freq) <= tol
                ]
                if candidates:
                    best_gen, best_se, best_freq = max(candidates, key=lambda x: x[1])
                else:
                    # –µ—Å–ª–∏ –Ω–∏ –æ–¥–Ω–æ –Ω–µ –ø—Ä–æ—à–ª–æ –ø–æ –¥–æ–ø—É—Å–∫—É ‚Äî –±–µ—Ä—ë–º –ø—Ä–æ—Å—Ç–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é SE
                    best_gen = int(np.argmax(best_se_hist))
                    best_se, best_freq = best_se_hist[best_gen], best_freq_hist[best_gen]

                # —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –ª—É—á—à–∏–π –∏–Ω–¥–∏–≤–∏–¥
                best_ind = best_inds[best_gen]
                se, ghz, refl, absor = predict_em_properties(
                    model, x_scaler, y_scaler, *best_ind
                )

                # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                st.success("üéØ –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞–π–¥–µ–Ω—ã:")
                st.write(f"‚Ä¢ H,K,L,P = {np.round(best_ind, 6).tolist()}")
                st.write(f"‚Ä¢ –≠–≠ = {se:.2f} –¥–ë")
                st.write(f"‚Ä¢ Freq = {ghz:.4f} –ì–ì—Ü")
                st.write(f"‚Ä¢ Reflection = {refl:.4f}, Absorption = {absor:.4f}")

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Å–µ—Å—Å–∏–∏ –∏ –≤ –ë–î
                st.session_state.ga_result = {
                    'params': list(best_ind), 'se': se, 'ghz': ghz,
                    'refl': refl, 'absor': absor
                }
                save_ga_result(conn, structure, best_ind, se, ghz, refl, absor,
                            pop_size, generations, mutation_rate)

                # üñº –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ —ç–≤–æ–ª—é—Ü–∏–∏

                # 1) –≠–≤–æ–ª—é—Ü–∏—è SE –∏ —á–∞—Å—Ç–æ—Ç—ã
                fig, ax1 = plt.subplots(figsize=(10, 5))
                ax1.set_xlabel("–ü–æ–∫–æ–ª–µ–Ω–∏–µ")
                ax1.set_ylabel("–≠–≠, –¥–ë")
                ax1.plot(
                    range(1, len(best_se_hist) + 1),
                    best_se_hist,
                    label="–≠–≠ –ª—É—á—à–µ–π –æ—Å–æ–±–∏",
                    marker='o', markersize=3
                )
                ax1.grid(True)

                ax2 = ax1.twinx()
                ax2.set_ylabel("–ß–∞—Å—Ç–æ—Ç–∞, –ì–ì—Ü")
                ax2.plot(
                    range(1, len(best_freq_hist) + 1),
                    best_freq_hist,
                    label="–ß–∞—Å—Ç–æ—Ç–∞ –ª—É—á—à–µ–π –æ—Å–æ–±–∏",
                    marker='s', markersize=3, linestyle='--'
                )
                ax2.ticklabel_format(style='plain', useOffset=False)
                ax2.axhline(
                    y=target_freq, color='green', linestyle=':',
                    label=f'–¶–µ–ª–µ–≤–∞—è —á–∞—Å—Ç–æ—Ç–∞: {target_freq:.2f} –ì–ì—Ü'
                )

                # —Ä–∏—Å—É–µ–º ¬´–∑–≤—ë–∑–¥–æ—á–∫–∏¬ª –≤ –ª—É—á—à–µ–º –ø–æ–∫–æ–ª–µ–Ω–∏–∏
                x_star     = best_gen + 1
                y_se_star   = best_se_hist[best_gen]
                y_freq_star = best_freq_hist[best_gen]

                ax1.scatter(
                    [x_star], [y_se_star],
                    color='red', s=100, marker='*',
                    label=f'–ò—Ç–æ–≥–æ–≤–∞—è –≠–≠: {y_se_star:.2f} –¥–ë'
                )
                ax2.scatter(
                    [x_star], [y_freq_star],
                    color='purple', s=100, marker='*',
                    label=f'–ò—Ç–æ–≥–æ–≤–∞—è Freq: {y_freq_star:.4f} –ì–ì—Ü'
                )

                fig.suptitle("–≠–≤–æ–ª—é—Ü–∏—è –ì–ê: –≠–≠ –∏ —á–∞—Å—Ç–æ—Ç–∞")
                fig.tight_layout()

                # –ª–µ–≥–µ–Ω–¥–∞ –∏–∑ –æ–±–æ–∏—Ö –æ—Å–µ–π
                lines1, labels1 = ax1.get_legend_handles_labels()
                lines2, labels2 = ax2.get_legend_handles_labels()
                ax1.legend(
                    lines1 + lines2,
                    labels1 + labels2,
                    loc='upper left', bbox_to_anchor=(0.1, 0.95)
                )
                st.pyplot(fig)

                # 2) –≠–≤–æ–ª—é—Ü–∏—è —Ñ–∏—Ç–Ω–µ—Å-—Ñ—É–Ω–∫—Ü–∏–∏
                fig2, ax3 = plt.subplots(figsize=(10, 5))
                ax3.set_xlabel("–ü–æ–∫–æ–ª–µ–Ω–∏–µ")
                ax3.set_ylabel("–ó–Ω–∞—á–µ–Ω–∏–µ —Ñ–∏—Ç–Ω–µ—Å-—Ñ—É–Ω–∫—Ü–∏–∏")
                ax3.plot(
                    range(1, len(fit_hist) + 1),
                    fit_hist,
                    label="–§–∏—Ç–Ω–µ—Å –ª—É—á—à–µ–π –æ—Å–æ–±–∏",
                    marker='o', markersize=3
                )
                ax3.grid(True)
                fig2.suptitle("–≠–≤–æ–ª—é—Ü–∏—è –∑–Ω–∞—á–µ–Ω–∏—è —Ñ–∏—Ç–Ω–µ—Å-—Ñ—É–Ω–∫—Ü–∏–∏")
                fig2.tight_layout()
                ax3.legend()
                st.pyplot(fig2)

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥—Ä–∞—Ñ –≤ –ë–î
                buf = BytesIO()
                fig.savefig(buf, format='png')
                buf.seek(0)
                try:
                    save_graph_to_db(conn, "training_graphs_ga", structure,
                    buf.read(), "GA Evolution")                    
                    st.success(f"–ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ –ë–î")
                except Exception as db_e:
                    st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫ –≤ –ë–î: {db_e}")

            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ì–ê: {e}")


    # ===== TAB 3: –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ =====
    with tabs[2]:
        st.subheader("üß† –û–±—É—á–µ–Ω–∏–µ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏")
        structure = st.selectbox("–§–æ—Ä–º–∞", STRUCTURES, key="tab3_structure")
        input_file = f"./{structure}/cst_data.txt"

        batch_size = st.number_input("–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏", 16, 256, 64, 16)
        epochs     = st.number_input("–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏",     10, 500, 200, 10)
        log_out    = st.empty()

        if st.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ", key="tab3_train"):
            try:
                # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
                with open(input_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                X = np.array([[i['H'], i['K'], i['L'], i['P']] for i in data], np.float32)
                Y = np.array([[i['SE'], i['GHz'], i['Reflection'], i['Absorption']] for i in data], np.float32)

                # –†–∞–∑–±–∏–µ–Ω–∏–µ –∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
                X_tr, X_val, Y_tr, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)
                xs, ys = StandardScaler(), StandardScaler()
                X_tr_s, X_val_s = xs.fit_transform(X_tr), xs.transform(X_val)
                Y_tr_s, Y_val_s = ys.fit_transform(Y_tr), ys.transform(Y_val)

                # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –¥–ª—è –º–æ–¥–µ–ª–∏ –∏ —Å–∫–µ–π–ª–µ—Ä–æ–≤
                unique_id    = datetime.now().strftime("%Y%m%d_%H%M%S")
                model_path   = f"./models/{structure}/model_{unique_id}.keras"
                scalers_path = f"./models/{structure}/scalers_{unique_id}.pkl"

                # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
                model = tf.keras.Sequential([
                    tf.keras.layers.Dense(256, input_shape=(4,)),
                    tf.keras.layers.LeakyReLU(0.1),
                    tf.keras.layers.BatchNormalization(),
                    tf.keras.layers.Dense(128),
                    tf.keras.layers.Dense(64),
                    tf.keras.layers.Dense(32),
                    tf.keras.layers.Dense(4),
                ])
                model.compile(
                    optimizer=tf.keras.optimizers.Adam(),
                    loss="mean_squared_error",
                    metrics=['accuracy', 'mean_absolute_error', 'mean_squared_error']
                )

                # Callback –¥–ª—è –ª–æ–≥–æ–≤ –∏ —Ä–∞–Ω–Ω–µ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø–æ —Ç–æ—á–Ω–æ—Å—Ç–∏
                class StreamlitLogger(tf.keras.callbacks.Callback):
                    def __init__(self, output_element):
                        super().__init__()
                        self.output_element = output_element
                        self.log_text = ""
                    def on_epoch_end(self, epoch, logs=None):
                        acc     = logs.get('accuracy', 0) * 100
                        val_acc = logs.get('val_accuracy', 0) * 100
                        loss    = logs.get('loss', 0)
                        self.log_text += (
                            f"–≠–ø–æ—Ö–∞ {epoch+1}: loss={loss:.4f}, "
                            f"–¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –æ–±—É—á–µ–Ω–∏–∏={acc:.2f}%, –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏={val_acc:.2f}%\n"
                        )
                        self.output_element.text_area(
                            "üìú –õ–æ–≥ –æ–±—É—á–µ–Ω–∏—è", value=self.log_text, height=300
                        )

                callbacks = [
                    tf.keras.callbacks.EarlyStopping(
                        monitor='val_accuracy',
                        mode='max',
                        patience=10,
                        restore_best_weights=True,
                        verbose=1
                    ),
                    tf.keras.callbacks.ModelCheckpoint(
                        filepath=model_path,
                        monitor='val_accuracy',
                        mode='max',
                        save_best_only=True,
                        verbose=1
                    ),
                    StreamlitLogger(log_out)
                ]

                # –û–±—É—á–µ–Ω–∏–µ
                history = model.fit(
                    X_tr_s, Y_tr_s,
                    validation_data=(X_val_s, Y_val_s),
                    batch_size=batch_size,
                    epochs=epochs,
                    callbacks=callbacks,
                    verbose=0
                )

                # –û—Ü–µ–Ω–∫–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏ —Å–∫–µ–π–ª–µ—Ä–æ–≤
                pred_s = model.predict(X_val_s)
                pred   = ys.inverse_transform(pred_s)
                mse    = mean_squared_error(Y_val, pred)
                mae    = mean_absolute_error(Y_val, pred)
                r2     = r2_score(Y_val, pred)
                model.save(model_path)
                joblib.dump((xs, ys), scalers_path)
                
                now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                save_trained_model_to_db(conn, structure, unique_id, mse, mae, r2, model_path, scalers_path, run_date=now)

                st.success("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
                st.write(f"–ò—Ç–æ–≥–æ–≤–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {history.history['accuracy'][-1]*100:.2f}%, "
                         f"–í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {history.history['val_accuracy'][-1]*100:.2f}%")
                st.write(f"MSE={mse:.4f}, MAE={mae:.4f}, R2={r2:.4f}")

                # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω–æ–≥–æ –≥—Ä–∞—Ñ–∏–∫–∞ –º–µ—Ç—Ä–∏–∫
                fig, axes = plt.subplots(3, 1, figsize=(10, 18))
                # ‚Äî Accuracy
                axes[0].plot([x * 100 for x in history.history['accuracy']],     label='Train Accuracy')
                axes[0].plot([x * 100 for x in history.history['val_accuracy']], label='Val Accuracy')
                axes[0].set_title('–ì—Ä–∞—Ñ–∏–∫ —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ , %')
                axes[0].set_xlabel('–≠–ø–æ—Ö–∞')
                axes[0].set_ylabel('–¢–æ—á–Ω–æ—Å—Ç—å, %')
                axes[0].legend()
                # ‚Äî MSE (loss)
                axes[1].plot(history.history['loss'],     label='Train MSE')
                axes[1].plot(history.history['val_loss'], label='Val MSE')
                axes[1].set_title('–°—Ä–µ–¥–Ω–µ–∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–∞—è –æ—à–∏–±–∫–∞ (MSE)')
                axes[1].set_xlabel('–≠–ø–æ—Ö–∞')
                axes[1].set_ylabel('MSE')
                axes[1].legend()
                # ‚Äî MAE
                axes[2].plot(history.history['mean_absolute_error'],     label='Train MAE')
                axes[2].plot(history.history['val_mean_absolute_error'], label='Val MAE')
                axes[2].set_title('–°—Ä–µ–¥–Ω—è—è –∞–±—Å–æ–ª—é—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ (MAE)')
                axes[2].set_xlabel('–≠–ø–æ—Ö–∞')
                axes[2].set_ylabel('MAE')
                axes[2].legend()

                fig.tight_layout()
                st.pyplot(fig)

                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞ –≤ –ë–î
                buf = BytesIO()
                fig.savefig(buf, format='png')
                buf.seek(0)
                
                try:
                    save_graph_to_db(conn, "training_graphs_tf", structure, buf.read(), f"train_metrics_{unique_id}", run_date= now)
                    st.success(f"–ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ –ë–î")
                except Exception as db_e:
                    st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫ –≤ –ë–î: {db_e}")

            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {e}")
                
        # ===== TAB 4: –°–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏ –ì–ê =====
    with tabs[3]:
        st.subheader("üñºÔ∏è –°–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ì–ê")
        # –≤—ã–±–æ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        structure_filter = st.selectbox(
            "–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–æ—Ä–º—É –º–µ—Ç–∞—ç–ª–µ–º–µ–Ω—Ç–∞",
            STRUCTURES,
            key="tab4_structure"
        )

        # 1) –¥–æ—Å—Ç–∞—ë–º –∏–∑ –ë–î –≤—Å–µ –≥—Ä–∞—Ñ–∏–∫–∏ –ì–ê (—Å –ø–æ–ª–µ–º structure –≤–Ω—É—Ç—Ä–∏)
        all_graphs = get_training_graphs(conn, "training_graphs_ga")
        # 2) —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ
        graphs = [
            (run_date, name, blob)
            for run_date, struct, name, blob in all_graphs
            if struct == structure_filter
        ]

        # 3) –µ—Å–ª–∏ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –Ω–µ—Ç ‚Äî –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∞–µ–º
        if not graphs:
            st.info(f"–î–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã **{DISPLAY_NAMES[structure_filter]}** –µ—â—ë –Ω–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤ –ì–ê.")
        else:
            # 4) –≥—Ä—É–ø–ø–∏—Ä—É–µ–º –∏—Ö –ø–æ –¥–∞—Ç–µ
            graph_dict = {}
            for run_date, name, blob in graphs:
                graph_dict.setdefault(run_date, []).append((name, blob))

            # 5) –≤—ã—Ç—è–≥–∏–≤–∞–µ–º –∏–∑ ga_results –≤—Å–µ —Å—Ç—Ä–æ—á–∫–∏ –ø–æ —ç—Ç–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ
            df = pd.read_sql_query(
                "SELECT * FROM ga_results WHERE structure=? ORDER BY run_date DESC",
                conn, params=(structure_filter,)
            )

            if df.empty:
                st.info("–•–æ—Ç—è –≥—Ä–∞—Ñ–∏–∫–∏-—Ç–æ –µ—Å—Ç—å, –Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ GA –µ—â—ë –Ω–µ—Ç. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é.")
            else:
                # —Ä–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º JSON-–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
                df["params"] = df["params"].apply(json.loads)
                df[["H","K","L","P"]] = pd.DataFrame(df["params"].tolist(), index=df.index)

                # –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–∏ –¥–µ–ª–∞–µ–º –±–ª–æ–∫ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∏ —á–µ–∫–±–æ–∫—Å–æ–º
                for idx, row in df.iterrows():
                    st.markdown("---")
                    st.markdown(f"**üïí –î–∞—Ç–∞:** `{row['run_date']}`")
                    st.markdown(
                        f"**SE:** {row['se']:.4f} –¥–ë | "
                        f"**Freq:** {row['ghz']:.4f} –ì–ì—Ü | "
                        f"**Refl:** {row['refl']:.4f} | "
                        f"**Absor:** {row['absor']:.4f}"
                    )
                    st.markdown(
                        f"**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã H,K,L,P:** "
                        f"{row['H']:.4f}, {row['K']:.4f}, "
                        f"{row['L']:.4f}, {row['P']:.4f}"
                    )

                    show = st.checkbox("üìà –ü–æ–∫–∞–∑–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫–∏ —ç—Ç–æ–≥–æ –∑–∞–ø—É—Å–∫–∞", key=f"show_ga_{idx}")
                    if show:
                        for name, blob in graph_dict.get(row["run_date"], []):
                            st.image(blob, caption=f"{name} ({row['run_date']})", use_container_width=True)


    # ===== TAB 5: –°–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏ TF =====
    with tabs[4]:
        st.subheader("üñºÔ∏è –°–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏ –º–æ–¥–µ–ª–∏ TF")
        # –≤—ã–±–æ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        structure_filter_tf = st.selectbox(
            "–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–æ—Ä–º—É –º–µ—Ç–∞—ç–ª–µ–º–µ–Ω—Ç–∞",
            STRUCTURES,
            key="tab5_structure"
        )

        # 1) –≤—ã—Ç–∞—Å–∫–∏–≤–∞–µ–º –≤—Å–µ –≥—Ä–∞—Ñ–∏–∫–∏ TF
        all_graphs_tf = get_training_graphs(conn, "training_graphs_tf")
        # 2) —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ
        graphs_tf = [
            (run_date, name, blob)
            for run_date, struct, name, blob in all_graphs_tf
            if struct == structure_filter_tf
        ]

        if not graphs_tf:
            st.info(f"–î–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã **{DISPLAY_NAMES[structure_filter_tf]}** –µ—â—ë –Ω–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤ TF.")
        else:
            # –≥—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ
            graph_dict_tf = {}
            for run_date, name, blob in graphs_tf:
                graph_dict_tf.setdefault(run_date, []).append((name, blob))

            # 3) –≤—ã—Ç—è–≥–∏–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ trained_models_tf
            tf_df = pd.read_sql_query(
                "SELECT * FROM trained_models_tf WHERE structure=? ORDER BY run_date DESC",
                conn, params=(structure_filter_tf,)
            )

            if tf_df.empty:
                st.info("–ú–µ—Ç—Ä–∏–∫ –º–æ–¥–µ–ª–µ–π TF –µ—â—ë –Ω–µ—Ç. –û–±—É—á–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω—É –º–æ–¥–µ–ª—å.")
            else:
                for idx, row in tf_df.iterrows():
                    st.markdown("---")
                    st.markdown(f"**üïí –î–∞—Ç–∞:** {row['run_date']}")
                    st.markdown(
                        f"**MSE:** {row['mse']:.4f} | "
                        f"**MAE:** {row['mae']:.4f} | "
                        f"**R¬≤:** {row['r2']:.4f}"
                    )

                    show = st.checkbox("üìà –ü–æ–∫–∞–∑–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫–∏ —ç—Ç–æ–≥–æ –∑–∞–ø—É—Å–∫–∞", key=f"show_tf_{idx}")
                    if show:
                        for name, blob in graph_dict_tf.get(row["run_date"], []):
                            st.image(blob, caption=f"{name} ({row['run_date']})", use_container_width=True)


if __name__ == "__main__":
    run_app()
